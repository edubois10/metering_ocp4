{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import datetime as datetime\n",
    "\n",
    "\n",
    "from koku_to_cs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendDataframesWithGoodFormat(df1,df2):\n",
    "        \n",
    "    report_df = df1.append(df2)\n",
    "    \n",
    "    report_df[\"Amount\"] = ''\n",
    "    report_df[\"Currency\"] = ''\n",
    "    report_df[\"Evidence3\"] = report_df[\"Evidence3\"].astype(float)\n",
    "    report_df[\"Evidence4\"] = report_df[\"Evidence4\"].astype(float)\n",
    "    report_df[\"Unweighted_Volume\"] = report_df[\"Unweighted_Volume\"].astype(float)\n",
    "    report_df[\"Evidence1\"] = report_df[\"Evidence1\"].apply(lambda x: str(x).lower())\n",
    "\n",
    "    report_df_without_volume = report_df[report_df['Evidence2_DomainID'] != 'Application Namespace_Storage']\n",
    "    report_df_without_volume = report_df_without_volume.groupby(['Consumption_Type','Sender_DomainID','Sender_Region','Sender_ObjectID','Sender_OptionID','Receiver_Office','Evidence1_DomainID','Evidence1','Evidence2_DomainID','Evidence2','Evidence3_DomainID','Evidence4_DomainID','Amount','Currency','Month','Year','Scenario','Booking_Costtype'], as_index=False).sum()\n",
    "    report_df_without_volume = report_df_without_volume[['Consumption_Type','Sender_DomainID','Sender_Region','Sender_ObjectID','Sender_OptionID','Receiver_Office','Evidence1_DomainID','Evidence1','Evidence2_DomainID','Evidence2','Evidence3_DomainID','Evidence3','Evidence4_DomainID','Evidence4','Unweighted_Volume','Amount','Currency','Month','Year','Scenario','Booking_Costtype']]\n",
    "\n",
    "\n",
    "    report_df_only_volume = report_df[report_df['Evidence2_DomainID'] == 'Application Namespace_Storage']\n",
    "    report_df_only_volume = report_df_only_volume.groupby(['Consumption_Type','Sender_DomainID','Sender_Region','Sender_ObjectID','Sender_OptionID','Receiver_Office','Evidence1_DomainID','Evidence1','Evidence2_DomainID','Evidence2','Evidence3_DomainID','Evidence4_DomainID','Amount','Currency','Month','Year','Scenario','Booking_Costtype'], as_index=False).mean()\n",
    "    report_df_only_volume = report_df_only_volume[['Consumption_Type','Sender_DomainID','Sender_Region','Sender_ObjectID','Sender_OptionID','Receiver_Office','Evidence1_DomainID','Evidence1','Evidence2_DomainID','Evidence2','Evidence3_DomainID','Evidence3','Evidence4_DomainID','Evidence4','Unweighted_Volume','Amount','Currency','Month','Year','Scenario','Booking_Costtype']]\n",
    "\n",
    "\n",
    "    appended_report = report_df_without_volume.append(report_df_only_volume)\n",
    "\n",
    "    return appended_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading files generated by Koku after unzipping them\n",
    "\n",
    "path = '../reports/upload/'\n",
    "files = glob.glob(path + '/*.csv')\n",
    "\n",
    "'''\n",
    "Not First day of the month.\n",
    "1fd80ead-0244-4464-8815-f561d1f7bf54_openshift_usage_report.0.csv 0 -> namespace information\n",
    "1fd80ead-0244-4464-8815-f561d1f7bf54_openshift_usage_report.1.csv 1 -> node information\n",
    "1fd80ead-0244-4464-8815-f561d1f7bf54_openshift_usage_report.2.csv 2 -> pod information\n",
    "1fd80ead-0244-4464-8815-f561d1f7bf54_openshift_usage_report.3.csv 3 -> volume information\n",
    "\n",
    "First day of the month\n",
    "56dc60a4-e6d8-4350-8126-5e6b3f10b7ad_openshift_usage_report.0.csv # Previous Month\n",
    "56dc60a4-e6d8-4350-8126-5e6b3f10b7ad_openshift_usage_report.1.csv # Current Month\n",
    "56dc60a4-e6d8-4350-8126-5e6b3f10b7ad_openshift_usage_report.2.csv # Previous Month\n",
    "56dc60a4-e6d8-4350-8126-5e6b3f10b7ad_openshift_usage_report.3.csv # Current Month\n",
    "56dc60a4-e6d8-4350-8126-5e6b3f10b7ad_openshift_usage_report.4.csv # Previous Month\n",
    "56dc60a4-e6d8-4350-8126-5e6b3f10b7ad_openshift_usage_report.5.csv # Current Month\n",
    "56dc60a4-e6d8-4350-8126-5e6b3f10b7ad_openshift_usage_report.6.csv # Previous Month\n",
    "56dc60a4-e6d8-4350-8126-5e6b3f10b7ad_openshift_usage_report.7.csv # Current Month\n",
    "'''\n",
    "\n",
    "namespace_path = glob.glob(path + '/*0.csv')[0]\n",
    "node_path = glob.glob(path + '/*2.csv')[0]\n",
    "pod_path = glob.glob(path + '/*4.csv')[0]\n",
    "volume_path = glob.glob(path + '/*6.csv')[0]\n",
    "\n",
    "\n",
    "namespace_data_raw = pd.read_csv(namespace_path)\n",
    "node_data_raw = pd.read_csv(node_path)\n",
    "node_data_raw_bis = pd.read_csv(node_path)\n",
    "pod_data_raw = pd.read_csv(pod_path)\n",
    "volume_data_raw = pd.read_csv(volume_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edubois/RedHat/Engagements/CreditSuisse/2021/koku-metrics-operator/jupyterNotebooks/koku_to_cs.py:196: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  namespace_data[\"namespace_labels\"] = namespace_data[\"namespace_labels\"].astype(str)\n",
      "/home/edubois/RedHat/Engagements/CreditSuisse/2021/koku-metrics-operator/jupyterNotebooks/koku_to_cs.py:370: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  volume_request_storage_gigabytes = volume_data.loc[((volume_data['namespace'] == namespace) & (volume_data['volume_request_storage_gigabytes'] > 0))].mean().volume_request_storage_gigabytes\n"
     ]
    }
   ],
   "source": [
    "# Loading files generated by Koku after unzipping them\n",
    "isfile = os.path.isfile\n",
    "path = '../reports_new/upload/'\n",
    "files = glob.glob(path + '/*.csv')\n",
    "\n",
    "# Checking how many file there was in the tar file from the koku report.\n",
    "# Normally there should be 4 csv files each corresponding to namespace data, node data, pod data, volume data\n",
    "if len(files) == 4:\n",
    "    namespace_path = glob.glob(path + '/*0.csv')[0]\n",
    "    node_path = glob.glob(path + '/*1.csv')[0]\n",
    "    pod_path = glob.glob(path + '/*2.csv')[0]\n",
    "    volume_path = glob.glob(path + '/*3.csv')[0]\n",
    "\n",
    "\n",
    "    namespace_data_raw = pd.read_csv(namespace_path)\n",
    "    node_data_raw = pd.read_csv(node_path)\n",
    "    node_data_raw_bis = pd.read_csv(node_path)\n",
    "    pod_data_raw = pd.read_csv(pod_path)\n",
    "    volume_data_raw = pd.read_csv(volume_path)\n",
    "    \n",
    "    metering_report_df = koku_to_cs(namespace_data_raw, node_data_raw, pod_data_raw, volume_data_raw)\n",
    "    \n",
    "    month = getMonth(namespace_data_raw)\n",
    "    report_path = '../CS_billing_reports/openshift_usage_month_{}_billing_report.csv'.format(month)\n",
    "    \n",
    "    if isfile(report_path):\n",
    "    \n",
    "        report_df = pd.read_csv(report_path)\n",
    "\n",
    "        appended_report = appendDataframesWithGoodFormat(report_df,metering_report_df)    \n",
    "        appended_report.to_csv(report_path, index=False)\n",
    "    \n",
    "    else:\n",
    "        metering_report_df.to_csv(report_path, index=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "# if there are 8 csv files, it should mean that the koku metering operator report have metrics for the last day of\n",
    "# a given month and metrics for the first day of a new month. 4 csv files for end of the month metrics, 4 csv files\n",
    "# for new month metrics.\n",
    "elif len(files) == 8:\n",
    "    \n",
    "    # check that the file are in the correct order\n",
    "    previous_month_path = glob.glob(path + '/*0.csv')[0]\n",
    "    current_month_path = glob.glob(path + '/*1.csv')[0]\n",
    "    \n",
    "    namespace_data_previous_month = pd.read_csv(previous_month_path)\n",
    "    namespace_data_current_month = pd.read_csv(current_month_path)\n",
    "    \n",
    "    if set(namespace_data_previous_month.columns) == set(namespace_data_current_month.columns):\n",
    "        \n",
    "        # Previous Month\n",
    "        namespace_previous_month_path = glob.glob(path + '/*0.csv')[0]\n",
    "        node_previous_month_path = glob.glob(path + '/*2.csv')[0]\n",
    "        pod_previous_month_path = glob.glob(path + '/*4.csv')[0]\n",
    "        volume_previous_month_path = glob.glob(path + '/*6.csv')[0]\n",
    "        \n",
    "        namespace_previous_month_data_raw = pd.read_csv(namespace_previous_month_path)\n",
    "        node_previous_month_data_raw = pd.read_csv(node_previous_month_path)\n",
    "        pod_previous_month_data_raw = pd.read_csv(pod_previous_month_path)\n",
    "        volume_previous_month_data_raw = pd.read_csv(volume_previous_month_path)\n",
    "        \n",
    "        metering_previous_month_report_df = koku_to_cs(namespace_previous_month_data_raw, node_previous_month_data_raw, pod_previous_month_data_raw, volume_previous_month_data_raw)\n",
    "\n",
    "        month = getMonth(namespace_previous_month_data_raw)\n",
    "        report_path = '../CS_billing_reports/openshift_usage_month_{}_billing_report.csv'.format(month)\n",
    "\n",
    "        if isfile(report_path):\n",
    "            report_df = pd.read_csv(report_path)\n",
    "\n",
    "            appended_report = appendDataframesWithGoodFormat(report_df,metering_previous_month_report_df)    \n",
    "            appended_report.to_csv(report_path, index=False)\n",
    "        \n",
    "        else:\n",
    "            metering_previous_month_report_df.to_csv(report_path, index=False)\n",
    "        \n",
    "        # New Month\n",
    "        namespace_current_month_path = glob.glob(path + '/*1.csv')[0]\n",
    "        node_current_month_path = glob.glob(path + '/*3.csv')[0]\n",
    "        pod_current_month_path = glob.glob(path + '/*5.csv')[0]\n",
    "        volume_current_month_path = glob.glob(path + '/*7.csv')[0]\n",
    "        \n",
    "        namespace_current_month_data_raw = pd.read_csv(namespace_current_month_path)\n",
    "        node_current_month_data_raw = pd.read_csv(node_current_month_path)\n",
    "        pod_current_month_data_raw = pd.read_csv(pod_current_month_path)\n",
    "        volume_current_month_data_raw = pd.read_csv(volume_current_month_path)\n",
    "    \n",
    "        metering_current_month_report_df = koku_to_cs(namespace_current_month_data_raw, node_current_month_data_raw, pod_current_month_data_raw, volume_current_month_data_raw)\n",
    "\n",
    "        month = getMonth(namespace_current_month_data_raw)\n",
    "        report_path = '../CS_billing_reports/openshift_usage_month_{}_billing_report.csv'.format(month)\n",
    "\n",
    "        if isfile(report_path):\n",
    "    \n",
    "            report_df = pd.read_csv(report_path)\n",
    "\n",
    "            appended_report = appendDataframesWithGoodFormat(report_df,metering_current_month_report_df)    \n",
    "            appended_report.to_csv(report_path, index=False)\n",
    "            \n",
    "        else:\n",
    "            metering_current_month_report_df.to_csv(report_path, index=False)\n",
    "    else:\n",
    "        raise Exception('Koku reports file naming is incorrect \\n Note: In a new month, if there is metering data from the previous month and the new month, the following file naming is expected: \\n <uid>_openshift_usage_report.0.csv  Namespace data Previous Month \\n <uid>_openshift_usage_report.1.csv  Namespace data Current Month \\n <uid>_openshift_usage_report.2.csv  Node data Previous Month \\n <uid>_openshift_usage_report.3.csv  Node data Current Month \\n <uid>_openshift_usage_report.4.csv  Pod data Previous Month \\n <uid>_openshift_usage_report.5.csv Pod data Current Month \\n <uid>_openshift_usage_report.6.csv  Volume data Previous Month \\n <uid>_openshift_usage_report.7.csv  Volume data Current Month')\n",
    "        \n",
    "else:\n",
    "    raise Exception('There are not enough or too many reports for the script to run. \\n Note: In a koku reports tar file, there should be 4 reports and on a new month if there is report month overlapping, there should be 8 reports')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
